{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f27a77-232a-4a18-9d9b-a521bb721674",
   "metadata": {},
   "source": [
    "# ADA Project : Milestone 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b6432",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d354a809-3775-419b-8e1f-a15e9d00e21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07585f1",
   "metadata": {},
   "source": [
    "### Conversion : txt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c393a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require extensive amount of RAM (a bit less than 32Gb)\n",
    "do_conversion = False\n",
    "if do_conversion:\n",
    "    ratings_text_to_csv(\"./data/BeerAdvocate/ratings.txt\")\n",
    "    ratings_text_to_csv(\"./data/RateBeer/ratings.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946a8fe",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3882cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeerAdvocate (BA)\n",
    "beers_BA, breweries_BA, users_BA, ratings_BA = load_data(\"BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3989b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RateBeer (RB)\n",
    "beers_RB, breweries_RB, users_RB, ratings_RB = load_data(\"RB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9708f392-044f-490a-9310-b443752ed092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mathi\\OneDrive\\etudes\\epfl\\MA1\\ADA\\Project\\ada-2023-project-dada\\utils.py:21: DtypeWarning: Columns (0,1,2,3,4,5,8,10,11,12,13,15,16,17,18,19,20,23,25,26,27,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  beers_MD = pd.read_table(\"./data/matched_beer_data/beers.csv\", sep=\",\")\n",
      "c:\\Users\\Mathi\\OneDrive\\etudes\\epfl\\MA1\\ADA\\Project\\ada-2023-project-dada\\utils.py:25: DtypeWarning: Columns (0,1,2,3,5,7,8,9,10,11,13,17,18,19,20,22,24,25,26,27,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_MD = pd.read_table(\"./data/matched_beer_data/ratings.csv\", sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "# Matched Dataset (MD)\n",
    "beers_MD, breweries_MD, users_MD, users_approx_MD, ratings_MD = load_data(\"MD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac45c9c",
   "metadata": {},
   "source": [
    "### Populate and merge data from BA and RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b4a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Require extensive amount of RAM (>20Gb)\n",
    "do_populate_merge = False\n",
    "if do_populate_merge:\n",
    "    \n",
    "    # Populate ratings with info from users, breweries and beers\n",
    "    ratings_populated_BA = populate_ratings(ratings_BA, users_BA, breweries_BA, beers_BA, \"BA\")\n",
    "    ratings_populated_RB = populate_ratings(ratings_RB, users_RB, breweries_RB, beers_RB, \"RB\")\n",
    "\n",
    "    # Merge populated ratings\n",
    "    merged_ratings_path = \"./data/ratings_BA_RB.csv\"\n",
    "    ratings_mixed = merge_populated_ratings(ratings_populated_BA, ratings_populated_RB, merged_ratings_path)\n",
    "\n",
    "    # Save subsample of rating (easier to handle on laptops)\n",
    "    merged_ratings_sample_path = \"./data/ratings_BA_RB_sample.csv\"\n",
    "    save_subsample(dataframe=ratings_mixed, save_path = merged_ratings_sample_path, frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc626ba4",
   "metadata": {},
   "source": [
    "### Load populated merged ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb59e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/ratings_BA_RB_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mathi\\OneDrive\\etudes\\epfl\\MA1\\ADA\\Project\\ada-2023-project-dada\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mathi/OneDrive/etudes/epfl/MA1/ADA/Project/ada-2023-project-dada/main.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# ratings_mixed = pd.read_table(\"./data/ratings_BAm_RBm.csv\", sep=\",\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mathi/OneDrive/etudes/epfl/MA1/ADA/Project/ada-2023-project-dada/main.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ratings_mixed_sample \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_table(\u001b[39m\"\u001b[39;49m\u001b[39m./data/ratings_BA_RB_sample.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Mathi\\anaconda3\\envs\\ADA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1282\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1269\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1270\u001b[0m     dialect,\n\u001b[0;32m   1271\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m   1279\u001b[0m )\n\u001b[0;32m   1280\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1282\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Mathi\\anaconda3\\envs\\ADA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Mathi\\anaconda3\\envs\\ADA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Mathi\\anaconda3\\envs\\ADA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Mathi\\anaconda3\\envs\\ADA\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/ratings_BA_RB_sample.csv'"
     ]
    }
   ],
   "source": [
    "# ratings_mixed = pd.read_table(\"./data/ratings_BAm_RBm.csv\", sep=\",\")\n",
    "ratings_mixed_sample = pd.read_table(\"./data/ratings_BA_RB_sample.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b4551",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444148d5",
   "metadata": {},
   "source": [
    "### Linear regression on subset of reviews\n",
    "Function that takes a subset of ratings and columns of interest as input and returns a Linear Regresion results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d39340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LR(data, columns):\n",
    "    # create formula and normalize data\n",
    "    formula = 'rating ~ ' + columns[0]\n",
    "    columns.append('rating')  # add rating for the linear regression\n",
    "    for idx, el in enumerate(columns):\n",
    "        if len(columns) - 1 > idx > 0:  # add feature to formula\n",
    "            formula += ' + ' + el\n",
    "        data[el] = (data[el] - data[el].mean())/data[el].std()  # standardization\n",
    "\n",
    "    data_to_process = data[columns].dropna().sample(frac=1)  # create a subset with the columns of interest and shuffle it\n",
    "    \n",
    "    # create the model and fit it to the dataset\n",
    "    mod = smf.ols(formula=formula, data=data_to_process)\n",
    "    np.random.seed(2)\n",
    "    res = mod.fit()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36558f",
   "metadata": {},
   "source": [
    "### Linear regression on the full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc62e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns:\n",
      " Index(['beer_name', 'beer_id', 'style', 'abv', 'nbr_ratings', 'nbr_reviews',\n",
      "       'avg', 'ba_score', 'bros_score', 'avg_computed', 'zscore',\n",
      "       'overall_score', 'style_score', 'nbr_matched_valid_ratings',\n",
      "       'avg_matched_valid_ratings', 'joined', 'brewery_name', 'brewery_id',\n",
      "       'brewery_location', 'nbr_beers', 'date', 'user_name', 'user_id',\n",
      "       'user_location', 'appearance', 'aroma', 'palate', 'taste', 'overall',\n",
      "       'rating', 'text', 'review', 'dataset'],\n",
      "      dtype='object')\n",
      "\n",
      "==============\n",
      "\n",
      "Chosen columns for linear regression are :\n",
      " ['appearance', 'aroma', 'palate', 'taste', 'overall']\n",
      "\n",
      "==============\n",
      "\n",
      "Results of the linear regression:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 rating   R-squared:                       0.796\n",
      "Model:                            OLS   Adj. R-squared:                  0.796\n",
      "Method:                 Least Squares   F-statistic:                 9.305e+05\n",
      "Date:                Thu, 16 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        21:59:32   Log-Likelihood:            -7.2937e+05\n",
      "No. Observations:             1189853   AIC:                         1.459e+06\n",
      "Df Residuals:                 1189847   BIC:                         1.459e+06\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1093      0.000   -266.977      0.000      -0.110      -0.109\n",
      "appearance     0.2426      0.001    450.924      0.000       0.242       0.244\n",
      "aroma          0.2974      0.001    296.694      0.000       0.295       0.299\n",
      "palate         0.4951      0.001    869.562      0.000       0.494       0.496\n",
      "taste          0.5240      0.001    420.068      0.000       0.522       0.526\n",
      "overall       -0.6926      0.001   -566.193      0.000      -0.695      -0.690\n",
      "==============================================================================\n",
      "Omnibus:                   205552.102   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           646966.329\n",
      "Skew:                          -0.892   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.142   Cond. No.                         6.58\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print('Initial columns:\\n', ratings_mixed_sample.columns)\n",
    "columns_of_interest = [\"appearance\",  \"aroma\",  \"palate\",  \"taste\",  \"overall\"]\n",
    "print('\\n==============\\n')\n",
    "print('Chosen columns for linear regression are :\\n', columns_of_interest)\n",
    "res = get_LR(ratings_mixed_sample, columns_of_interest)\n",
    "\n",
    "print('\\n==============\\n')\n",
    "print('Results of the linear regression:\\n')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "592978ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let' now sort the coefficients by absolute impact on the rating:\n",
      "overall    -0.692640\n",
      "taste       0.524010\n",
      "palate      0.495072\n",
      "aroma       0.297362\n",
      "appearance  0.242650\n",
      "Intercept  -0.109322\n"
     ]
    }
   ],
   "source": [
    "print('Let\\' now sort the coefficients by absolute impact on the rating:')\n",
    "print(pd.DataFrame(res.params).sort_values(0, ascending=False, key=abs).to_string(index=True, header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7f017",
   "metadata": {},
   "source": [
    "Params statistics user_location-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only reviews where user_location has at least 1000 reviews (Arbitrary)\n",
    "ratings_mixed_1000 = ratings_mixed_sample[ratings_mixed_sample.groupby('user_location')['user_location'].transform('size') > 1000]\n",
    "countries = ratings_mixed_1000.user_location.unique()\n",
    "param_df = res.params\n",
    "\n",
    "# Analysis of LR parameters among countries\n",
    "for country in countries:\n",
    "    country_df = ratings_mixed_1000.loc[ratings_mixed_1000['user_location']==country]\n",
    "    res = get_LR(country_df, columns_of_interest)\n",
    "    pd.concat((param_df, res.params), axis=1)\n",
    "\n",
    "# Params per country\n",
    "param_df.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be827b",
   "metadata": {},
   "source": [
    "### Results\n",
    "From what we can see of this preliminary analysis, some features are having almost 3 times the influence of others on the rating.\n",
    "Moreover, the R-squared of the fitted model is **0.796** which means that the regression explains roughly 80% of the variation in the variables which is indicating that this simple model alreay fit quite well the data. In the future of this project, we plan to try more complex architectures in order to get the most accurate representation of the impact of each variable.\n",
    "\n",
    "Let now see if this influence stays constant geographically.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334a4fa",
   "metadata": {},
   "source": [
    "### Number of review per day using rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f462d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming the file is named 'beer_ratings.csv' and is located in the same directory as your script.\n",
    "# Read the CSV file\n",
    "BA_NR_RW_DAY=ratings_BA\n",
    "# Convert the Unix time to a datetime object, assuming the 'date' column is Unix time in seconds\n",
    "BA_NR_RW_DAY['date'] = pd.to_datetime(BA_NR_RW_DAY['date'], unit='s')\n",
    "\n",
    "# Filter out dates to ensure we only have one year of data, if necessary\n",
    "start_date = \"2015-01-1\"  # start date in the example given (20th August 2015)\n",
    "end_date = \"2016-01-1\"    # end date, one year later\n",
    "BA_NR_RW_DAY_WW = BA_NR_RW_DAY[(BA_NR_RW_DAY['date'] >= start_date) & (BA_NR_RW_DAY['date'] <= end_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe9278-a59a-4497-84d1-23379d124fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the date and count the reviews\n",
    "def plot_rolling(df, window=7):\n",
    "    daily_reviews = df.groupby(df['date'].dt.date).size()\n",
    "    print(daily_reviews)\n",
    "    # Calculate the moving average with a window size of 7 to remove weeks days\n",
    "    rolling = daily_reviews.rolling(window=window, center=True)\n",
    "    rolling_average = rolling.mean()\n",
    "    \n",
    "    # Plot the rolling average\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    rolling_average.plot(title='Number of Reviews Per Day Over One Year')\n",
    "    \n",
    "    # Add labels and grid\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Number of Reviews')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "plot_rolling(BA_NR_RW_DAY_WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fc498-d51e-415e-a063-1cf9131d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_beers= ratings_BA[ratings_BA[\"brewery_id\"].isin(breweries_BA[breweries_BA['location']=='Germany']['id'])]\n",
    "german_beers['date'] = pd.to_datetime(german_beers['date'], unit='s')\n",
    "\n",
    "# Filter out dates to ensure we only have one year of data, if necessary\n",
    "start_date = \"2015-01-1\"  # start date in the example given (20th August 2015)\n",
    "end_date = \"2016-01-1\"    # end date, one year later\n",
    "\n",
    "german_beers_WW = german_beers[(german_beers['date'] >= start_date) & (german_beers['date'] <= end_date)]\n",
    "plot_rolling(german_beers_WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716fdcf-4e37-456d-8f28-2c93fe4f19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_users= ratings_BA[ratings_BA[\"user_id\"].isin(users_BA[users_BA['location']=='Germany']['user_id'])]\n",
    "#german_beers['date'] = pd.to_datetime(german_beers['date'], unit='s')\n",
    "\n",
    "# Filter out dates to ensure we only have one year of data, if necessary\n",
    "start_date = \"2015-01-1\"  # start date in the example given (20th August 2015)\n",
    "end_date = \"2016-01-1\"    # end date, one year later\n",
    "\n",
    "german_users_WW = german_users[(german_users['date'] >= start_date) & (german_users['date'] <= end_date)]\n",
    "plot_rolling(german_users_WW, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5ab19-11af-4559-95f5-41bad8938354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f44925d",
   "metadata": {},
   "source": [
    "### Alcohol by volume evolution in a mean year by country of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_reviews = ratings_mixed_sample[['date','user_location','abv']]\n",
    "alcohol_reviews = alcohol_reviews.dropna()\n",
    "\n",
    "alcohol_reviews.loc[:,'date'] = alcohol_reviews[['date']].apply(lambda x: pd.to_datetime(x, unit='s'))\n",
    "alcohol_reviews.loc[:,'time'] = alcohol_reviews.loc[:,'date'].apply(lambda x: x.year)\n",
    "alcohol_reviews = alcohol_reviews.drop(columns = \"date\")\n",
    "alcohol_reviews = alcohol_reviews[alcohol_reviews.groupby('user_location')['user_location'].transform('size') > 50000]\n",
    "alcohol_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1621c-46b9-4c61-a4ca-e5cff5ffc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abv = alcohol_reviews.groupby([\"user_location\", \"time\"]).var().reset_index()\n",
    "\n",
    "# Create a plot with multiple lines and legend\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for location in mean_abv[\"user_location\"].unique():\n",
    "    location_data = mean_abv[mean_abv[\"user_location\"] == location]\n",
    "    plt.plot(location_data[\"time\"], location_data[\"abv\"], label=location)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"ABV\")\n",
    "plt.ylim([0, 15])\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"ABV vs Time for Different User Locations\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a295da-f8a5-43bc-aca3-139916537e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_abv = alcohol_reviews.groupby([\"user_location\", \"time\"]).var().reset_index()\n",
    "mean_abv.groupby(\"user_location\").plot(x=\"time\", y='abv', kind='line', ylim=[0, 15], subplots=True, sharex=False, sharey=True, layout= (1, -1), stacked=True, use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062de40-3766-493f-b460-2ce051635360",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_reviews_global = alcohol_reviews.drop(columns='user_location')\n",
    "mean_abv = alcohol_reviews_global.groupby([\"time\"]).var().reset_index()\n",
    "mean_abv.plot(x=\"time\", y='abv', kind='line', ylim=[0, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0966c0-7959-43b1-ba7e-0fda3c16083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abv = alcohol_reviews.groupby([\"time\"]).median().reset_index()\n",
    "mean_abv.plot(x=\"time\", y='abv', kind='line', ylim=[0, 15] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0d101-880a-4ba7-bc1f-85ffde4d5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abv = alcohol_reviews.groupby([\"time\"]).std().reset_index()\n",
    "mean_abv.plot(x=\"time\", y='abv', kind='line', ylim=[0, 15] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385df3f",
   "metadata": {},
   "source": [
    "### Test of Bens idea 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7502a-adbe-4111-bcd5-9d1182c92dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have pandas DataFrames: ratings_BA, breweries_BA\n",
    "\n",
    "# 1. Calculate average ratings per brewery in ratings_BA\n",
    "avg_ratings = ratings_BA.groupby('brewery_id')['rating'].mean().reset_index()\n",
    "avg_ratings.rename(columns={'rating': 'average_rating'}, inplace=True)\n",
    "\n",
    "# 2. Rename columns in breweries_BA and filter out breweries with more than 200 beers\n",
    "breweries_BA.rename(columns={'id': 'brewery_id', 'nbr_beers': 'beer_count'}, inplace=True)\n",
    "filtered_breweries = breweries_BA[breweries_BA['beer_count'] <= 200]\n",
    "\n",
    "# 3. Analysis: Merge the dataframes for plotting\n",
    "analysis_df = pd.merge(avg_ratings, filtered_breweries[['brewery_id', 'beer_count']], on='brewery_id')\n",
    "\n",
    "# Create a line plot with a 95% confidence interval\n",
    "sns.lineplot(data=analysis_df, x='beer_count', y='average_rating', errorbar=('ci', 95))\n",
    "\n",
    "plt.xlabel('Number of Beers Produced (up to 200)')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Relationship between Number of Beers and Average Ratings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e97c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
